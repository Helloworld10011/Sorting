{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75d874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268edd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, gener, iters, opt, loss_fn, verbose= True, device= \"cuda:1\"):\n",
    "    for i in tqdm(range(iters), desc = 'tqdm() Progress Bar'):\n",
    "        (X, Y) = gener.com_get(64)\n",
    "        preds= model(torch.tensor(X, device = device, dtype= torch.float32))\n",
    "        loss= loss_fn(preds.transpose(1, 2), torch.tensor(Y, device = device))\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        if i % 5000 == 0 and verbose:\n",
    "            print(\"step %i: loss = %f\"%(i, loss.detach().cpu().numpy()))\n",
    "\n",
    "    print(\"final loss= %f\"%(loss.detach().cpu().numpy()))\n",
    "    \n",
    "\n",
    "class sort():\n",
    "    def __init__(self, len, ran):\n",
    "        self.len = len\n",
    "        self.ran= ran\n",
    "\n",
    "    def get(self, num_swaps, b):\n",
    "        sorted_seq = np.sort(np.random.choice(self.ran, [b, self.len]))\n",
    "        seq = np.copy(sorted_seq)\n",
    "        for _ in np.arange(num_swaps):\n",
    "            i = np.random.randint(self.len-1, size= (b,))\n",
    "            t= seq[np.arange(b), i]\n",
    "            seq[np.arange(b), i] = seq[np.arange(b), i+1]\n",
    "            seq[np.arange(b), i+1] = t\n",
    "        seq = np.diag(np.ones(self.ran))[seq]\n",
    "\n",
    "        return seq, sorted_seq\n",
    "    \n",
    "    def com_get(self, b):\n",
    "        seq= np.random.choice(self.ran, [b, self.len])\n",
    "        sorted_seq = np.sort(seq)\n",
    "        seq = np.diag(np.ones(self.ran))[seq]\n",
    "        \n",
    "        return seq, sorted_seq\n",
    "    \n",
    "class sort_proj():\n",
    "    def __init__(self, leng, ran):\n",
    "        self.len = leng\n",
    "        self.ran= ran\n",
    "        self.proj = np.random.randn(ran, ran) / np.sqrt(ran)\n",
    "\n",
    "    def get(self, num_swaps, b):\n",
    "        sorted_seq = np.sort(np.random.choice(self.ran, [b, self.len]))\n",
    "        seq = np.copy(sorted_seq)\n",
    "        for _ in np.arange(num_swaps):\n",
    "            i = np.random.randint(self.len-1, size= (b,))\n",
    "            t= seq[np.arange(b), i]\n",
    "            seq[np.arange(b), i] = seq[np.arange(b), i+1]\n",
    "            seq[np.arange(b), i+1] = t\n",
    "        seq = np.einsum('ijk,kl->ijl', np.diag(np.ones(self.ran))[seq], self.proj)\n",
    "\n",
    "        return seq, sorted_seq\n",
    "    \n",
    "    def com_get(self, b):\n",
    "        seq= np.random.choice(self.ran, [b, self.len])\n",
    "        sorted_seq = np.sort(seq)\n",
    "        seq = np.einsum('ijk,kl->ijl', np.diag(np.ones(self.ran))[seq], self.proj)\n",
    "        \n",
    "        return seq, sorted_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70705a86",
   "metadata": {},
   "source": [
    "### Without positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3d5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention_wthead_wtpos(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim, embed_dim, attn_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0\n",
    "        \n",
    "        self.embed= nn.Linear(input_dim, embed_dim, bias = False)\n",
    "        self.key = nn.Linear(embed_dim, attn_dim, bias = False)\n",
    "        self.query = nn.Linear(embed_dim, attn_dim, bias = False)\n",
    "        self.value = nn.Linear(embed_dim, attn_dim, bias = False)\n",
    "\n",
    "        self.n_head = num_heads\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim= input_dim\n",
    "        self.emd_dim = embed_dim\n",
    "        self.attn_dim = attn_dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        N, S, E = input.shape\n",
    "        assert (S, E) == (self.seq_len, self.input_dim), \"Wrong input!\"\n",
    "\n",
    "        X = self.embed(input)\n",
    "\n",
    "        Q = torch.reshape(self.query(X), (N, self.seq_len, self.n_head, self.attn_dim//self.n_head)).transpose(1 , 2)\n",
    "        K = torch.reshape(self.key(X), (N, self.seq_len, self.n_head, self.attn_dim//self.n_head)).transpose(1, 2)\n",
    "        V = torch.reshape(self.value(X), (N, self.seq_len, self.n_head, self.attn_dim//self.n_head)).transpose(1, 2)\n",
    "        scores= torch.matmul(Q, torch.transpose(K, 3, 2))/(self.attn_dim//self.n_head)**0.5\n",
    "\n",
    "        Y1 = torch.matmul(scores, V).transpose(1, 2).reshape(N, self.seq_len, self.attn_dim)\n",
    "        out_att = Y1 + input\n",
    "\n",
    "        return out_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb010679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate=  1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 373.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 5.092510\n",
      "learning rate=  2.1544346900318823e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 394.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.651713\n",
      "learning rate=  4.641588833612782e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 379.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.592185\n",
      "learning rate=  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 380.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.543100\n",
      "learning rate=  0.00021544346900318823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 396.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.542858\n",
      "learning rate=  0.00046415888336127773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 389.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.565570\n",
      "learning rate=  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 381.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.521830\n",
      "learning rate=  0.002154434690031882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 390.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.583722\n",
      "learning rate=  0.004641588833612777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 394.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.668959\n",
      "learning rate=  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 381.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss= 3.674258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in np.logspace(-5, -2, 10):\n",
    "    tran = MultiHeadAttention_wthead_wtpos(20, 200, 256, 200, 8)\n",
    "    tran.to(device= device)\n",
    "    gener= sort(20, 200)\n",
    "    opt = torch.optim.Adam(tran.parameters(), lr= lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    print(\"learning rate= \", (lr))\n",
    "    trainer(tran, gener, 5000, opt, loss_fn, verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f401702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:   0%|                                                                                                                                                 | 76/250000 [00:00<11:01, 378.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 5.250623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:   2%|██▉                                                                                                                                            | 5060/250000 [00:12<11:04, 368.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000: loss = 3.531013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:   4%|█████▋                                                                                                                                        | 10065/250000 [00:25<10:10, 392.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000: loss = 3.510970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:   6%|████████▌                                                                                                                                     | 15071/250000 [00:38<10:22, 377.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000: loss = 3.506469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:   8%|███████████▍                                                                                                                                  | 20067/250000 [00:52<10:18, 371.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000: loss = 3.549042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  10%|██████████████▏                                                                                                                               | 25063/250000 [01:04<10:38, 352.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000: loss = 3.501200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  12%|█████████████████                                                                                                                             | 30074/250000 [01:18<09:36, 381.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000: loss = 3.516410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  14%|███████████████████▉                                                                                                                          | 35065/250000 [01:31<09:22, 382.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000: loss = 3.485808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  16%|██████████████████████▊                                                                                                                       | 40071/250000 [01:43<08:54, 392.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000: loss = 3.522886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  18%|█████████████████████████▌                                                                                                                    | 45073/250000 [01:56<08:42, 392.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000: loss = 3.541285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  20%|████████████████████████████▍                                                                                                                 | 50057/250000 [02:10<08:48, 378.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000: loss = 3.504151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  22%|███████████████████████████████▎                                                                                                              | 55060/250000 [02:23<08:19, 390.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55000: loss = 3.524684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  24%|██████████████████████████████████▏                                                                                                           | 60080/250000 [02:36<08:07, 389.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60000: loss = 3.572649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  26%|████████████████████████████████████▉                                                                                                         | 65072/250000 [02:48<08:08, 378.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65000: loss = 3.502911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  28%|███████████████████████████████████████▊                                                                                                      | 70052/250000 [03:01<07:46, 385.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 70000: loss = 3.539550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  30%|██████████████████████████████████████████▋                                                                                                   | 75046/250000 [03:14<07:19, 398.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 75000: loss = 3.515629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  32%|█████████████████████████████████████████████▍                                                                                                | 80040/250000 [03:27<07:45, 365.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 80000: loss = 3.550877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  34%|████████████████████████████████████████████████▎                                                                                             | 85049/250000 [03:40<06:58, 394.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 85000: loss = 3.507302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  36%|███████████████████████████████████████████████████▏                                                                                          | 90060/250000 [03:53<06:47, 392.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 90000: loss = 3.516448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  38%|█████████████████████████████████████████████████████▉                                                                                        | 95066/250000 [04:06<06:34, 392.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 95000: loss = 3.481259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  40%|████████████████████████████████████████████████████████▍                                                                                    | 100073/250000 [04:19<06:20, 393.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100000: loss = 3.527942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar:  42%|███████████████████████████████████████████████████████████                                                                                  | 104766/250000 [04:31<06:16, 385.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(tran\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtran\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 8\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, gener, iters, opt, loss_fn, verbose, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m loss\u001b[38;5;241m=\u001b[39m loss_fn(preds\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(Y, device \u001b[38;5;241m=\u001b[39m device))\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/anaconda3/envs/transf/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/transf/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/transf/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/transf/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transf/lib/python3.10/site-packages/torch/optim/adam.py:353\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# update step\u001b[39;00m\n\u001b[1;32m    351\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 5e-4\n",
    "tran = MultiHeadAttention_wthead_wtpos(20, 200, 256, 200, 8)\n",
    "tran.to(device= device)\n",
    "gener= sort(20, 200)\n",
    "opt = torch.optim.Adam(tran.parameters(), lr= lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "trainer(tran, gener, 250000, opt, loss_fn, verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34e92f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.086595\n"
     ]
    }
   ],
   "source": [
    "(X, Y) = gener.get(400, 10000)\n",
    "preds= tran(torch.tensor(X, device = device, dtype= torch.float32))\n",
    "preds= torch.argmax(preds, dim = 2).detach().cpu().numpy()\n",
    "\n",
    "print(np.sum(1*(Y == preds))/2e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ea77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
